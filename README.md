# ğŸ¤Ÿ SignBridge

> **Bridging the gap between sign language and voice â€” one gesture at a time.**

SignBridge is a Django + AI web app that uses your laptop or phone camera to detect sign language gestures in real time and convert them to **spoken voice** using Google Gemini Vision AI and the browser's Web Speech API.

---

## ğŸ“ Project Structure

```
signbridge/
â”œâ”€â”€ signbridge/          â† Django project config
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ wsgi.py
â”œâ”€â”€ translator/          â† Single Django app
â”‚   â”œâ”€â”€ models.py        â† DB models
â”‚   â”œâ”€â”€ admin.py         â† Admin panel
â”‚   â”œâ”€â”€ views.py         â† Views + AI integration
â”‚   â”œâ”€â”€ urls.py          â† URL routes
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ translator/
â”‚   â”‚       â”œâ”€â”€ base.html
â”‚   â”‚       â”œâ”€â”€ home.html
â”‚   â”‚       â”œâ”€â”€ translator.html  â† Main camera page
â”‚   â”‚       â”œâ”€â”€ history.html
â”‚   â”‚       â””â”€â”€ about.html
â”‚   â””â”€â”€ management/commands/seed_languages.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Setup & Run

### 1. Clone and install
```bash
git clone <your-repo>
cd signbridge
pip install -r requirements.txt
```

### 2. Set your Gemini API key
Get a free key at https://makersuite.google.com/app/apikey

```bash
export GEMINI_API_KEY="your-key-here"
```

Or edit `signbridge/settings.py`:
```python
GEMINI_API_KEY = 'your-key-here'
```

### 3. Run migrations
```bash
python manage.py makemigrations
python manage.py migrate
```

### 4. Seed sign languages
```bash
python manage.py seed_languages
```

### 5. Create admin user
```bash
python manage.py createsuperuser
```

### 6. Start the server
```bash
python manage.py runserver
```

Open http://127.0.0.1:8000

---

## ğŸ”— URL Routes

| URL | View | Description |
|-----|------|-------------|
| `/` | home | Landing page |
| `/translate/` | translator_view | Live camera + AI translator |
| `/history/` | history | Past sessions (auth required) |
| `/about/` | about | About page |
| `/api/analyze-frame/` | analyze_frame | POST â€” AI frame analysis |
| `/api/end-session/` | end_session | POST â€” close session |
| `/api/feedback/` | submit_feedback | POST â€” rate translation |
| `/admin/` | Django Admin | Full management panel |

---

## ğŸ¤– AI Integration

SignBridge uses **Google Gemini 1.5 Flash** (vision model) to:
1. Receive a base64 JPEG frame from the browser
2. Analyze hand position and gesture
3. Return: `detected_sign`, `translated_text`, `confidence_score`

The browser then uses the **Web Speech API** (`SpeechSynthesisUtterance`) to speak the translation aloud â€” no server-side audio needed.

**Demo mode**: If the Gemini API key is not set, a random demo response is returned so you can test the UI.

---

## ğŸ—„ï¸ Database Models

| Model | Purpose |
|-------|---------|
| `SignLanguageType` | ASL, BSL, KSL, etc. |
| `TranslationSession` | One camera session |
| `TranslationRecord` | Single detected sign + frame snapshot |
| `UserProfile` | Extended user info (role, preferences) |
| `Feedback` | Star ratings + correction data |

---

## ğŸŒ Supported Sign Languages
- ASL â€” American Sign Language
- BSL â€” British Sign Language
- KSL â€” Kenyan Sign Language *(Kenya officially recognizes KSL!)*
- IS â€” International Sign
- AUSLAN â€” Australian Sign Language